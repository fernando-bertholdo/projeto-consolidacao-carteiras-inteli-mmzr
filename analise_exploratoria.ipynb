{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados - Posição de Clientes MMZR\n",
    "\n",
    "Este notebook realiza uma análise exploratória inicial dos dados de posição de clientes. O objetivo é entender a estrutura do arquivo Excel fornecido, identificar colunas-chave e extrair insights preliminares para a consolidação das carteiras de investimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# OBRIGATÓRIO: Verificar se arquivo existe\n",
    "caminho_arquivo = './dados/posicao_de_clientes.xlsx'\n",
    "if not os.path.exists(caminho_arquivo):\n",
    "    print(f\"ERRO: Arquivo não encontrado: {caminho_arquivo}\")\n",
    "    print(\"Verifique se o arquivo está na pasta correta.\")\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_excel(caminho_arquivo)\n",
    "        print(f\"✅ Dataset carregado com sucesso: {df.shape[0]} linhas, {df.shape[1]} colunas\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao carregar arquivo: {e}\")\n",
    "        df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Estrutura Inicial dos Dados\n",
    "\n",
    "A primeira etapa é carregar os dados e realizar uma inspeção básica da sua estrutura, incluindo a identificação das colunas disponíveis, o formato geral do dataset e os tipos de dados de cada coluna. Também visualizamos as primeiras linhas para ter uma ideia do conteúdo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBRIGATÓRIO: Verificar se dados foram carregados\n",
    "if df is not None:\n",
    "    print(\"=== ESTRUTURA DOS DADOS ===\")\n",
    "    print(\"Colunas disponíveis:\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        print(f\"  {i+1}. {col}\")\n",
    "    \n",
    "    print(f\"\n",
    "Formato dos dados: {df.shape}\")\n",
    "    print(f\"Tipos de dados:\n",
    "{df.dtypes}\")\n",
    "    \n",
    "    print(\"\n",
    "=== PRIMEIRAS 3 LINHAS ===\")\n",
    "    display(df.head(3))\n",
    "    \n",
    "    # IDENTIFICAR possíveis colunas de cliente, valor, classe de ativo\n",
    "    colunas_possiveis = {\n",
    "        'cliente': [col for col in df.columns if any(term in col.lower() for term in ['cliente', 'client', 'nome'])],\n",
    "        'valor': [col for col in df.columns if any(term in col.lower() for term in ['valor', 'pl', 'patrimonio', 'saldo', 'montante'])],\n",
    "        'classe': [col for col in df.columns if any(term in col.lower() for term in ['classe', 'ativo', 'estrategia', 'produto'])]\n",
    "    }\n",
    "    \n",
    "    print(\"\n",
    "=== COLUNAS IDENTIFICADAS ===\")\n",
    "    for tipo, colunas in colunas_possiveis.items():\n",
    "        print(f\"{tipo.upper()}: {colunas}\")\n",
    "else:\n",
    "    print(\"❌ Não é possível analisar - dados não carregados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identificação de Clientes\n",
    "\n",
    "Analisamos a coluna de clientes para entender quantos clientes únicos existem e como os registros estão distribuídos entre eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # ASSUMIR que primeira coluna identificada como 'cliente' é a correta\n",
    "    # Se não encontrou, usar primeira coluna que contenha texto\n",
    "    coluna_cliente = None\n",
    "    if colunas_possiveis['cliente']:\n",
    "        coluna_cliente = colunas_possiveis['cliente'][0]\n",
    "    else:\n",
    "        # Buscar primeira coluna com dados tipo string/object\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == 'object':\n",
    "                coluna_cliente = col\n",
    "                break\n",
    "    \n",
    "    if coluna_cliente:\n",
    "        print(f\"=== ANÁLISE DE CLIENTES (usando coluna: {coluna_cliente}) ===\")\n",
    "        print(f\"Total de registros: {len(df)}\")\n",
    "        print(f\"Clientes únicos: {df[coluna_cliente].nunique()}\")\n",
    "        print(f\"Registros por cliente (média): {len(df) / df[coluna_cliente].nunique():.1f}\")\n",
    "        \n",
    "        # Mostrar alguns exemplos de clientes\n",
    "        print(f\"\n",
    "Exemplos de clientes:\")\n",
    "        clientes_unicos = df[coluna_cliente].unique()\n",
    "        for i, cliente in enumerate(clientes_unicos[:5]):\n",
    "            print(f\"  {i+1}. {cliente}\")\n",
    "        \n",
    "        if len(clientes_unicos) > 5:\n",
    "            print(f\"  ... e mais {len(clientes_unicos) - 5} clientes\")\n",
    "    else:\n",
    "        print(\"❌ Não foi possível identificar coluna de clientes\")\n",
    "        print(\"Colunas disponíveis:\", df.columns.tolist())\n",
    "else:\n",
    "    print(\"❌ Não é possível analisar - dados não carregados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise de Classes de Ativo e Classificação Local/Offshore\n",
    "\n",
    "Identificamos as diferentes classes de ativo presentes nos dados e tentamos classificá-las automaticamente como 'LOCAL', 'OFFSHORE' ou 'INDEFINIDO' com base em termos-chave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and coluna_cliente:\n",
    "    # Identificar coluna de classe de ativo\n",
    "    coluna_classe = None\n",
    "    if colunas_possiveis['classe']:\n",
    "        coluna_classe = colunas_possiveis['classe'][0]\n",
    "    else:\n",
    "        print(\"❌ Não foi possível identificar coluna de classes automaticamente\")\n",
    "        print(\"Colunas disponíveis:\", df.columns.tolist())\n",
    "        \n",
    "    if coluna_classe:\n",
    "        print(f\"=== ANÁLISE DE CLASSES DE ATIVO (usando coluna: {coluna_classe}) ===\")\n",
    "        classes_unicas = df[coluna_classe].value_counts()\n",
    "        print(f\"Total de classes diferentes: {len(classes_unicas)}\")\n",
    "        print(\"\n",
    "Distribuição de classes:\")\n",
    "        print(classes_unicas)\n",
    "        \n",
    "        # LÓGICA PARA SEPARAR LOCAL VS OFFSHORE\n",
    "        print(\"\n",
    "=== IDENTIFICAÇÃO LOCAL VS OFFSHORE ===\")\n",
    "        \n",
    "        # Termos que indicam carteira LOCAL (Brasil)\n",
    "        termos_local = ['pós', 'pos', 'inflação', 'inflacao', 'pré', 'pre', 'bancário', 'bancario', \n",
    "                       'cdi', 'ipca', 'selic', 'brasil', 'br', 'local']\n",
    "        \n",
    "        # Termos que indicam carteira OFFSHORE (Internacional)\n",
    "        termos_offshore = ['equity', 'equities', 'fixed income', 'bond', 'international', \n",
    "                          'global', 'usd', 'eur', 'offshore', 'exterior']\n",
    "        \n",
    "        # Classificar cada classe\n",
    "        classificacao = {}\n",
    "        for classe in classes_unicas.index:\n",
    "            classe_lower = str(classe).lower()\n",
    "            \n",
    "            # Verificar se contém termos locais\n",
    "            is_local = any(termo in classe_lower for termo in termos_local)\n",
    "            # Verificar se contém termos offshore\n",
    "            is_offshore = any(termo in classe_lower for termo in termos_offshore)\n",
    "            \n",
    "            if is_local and not is_offshore:\n",
    "                classificacao[classe] = 'LOCAL'\n",
    "            elif is_offshore and not is_local:\n",
    "                classificacao[classe] = 'OFFSHORE'\n",
    "            else:\n",
    "                classificacao[classe] = 'INDEFINIDO'\n",
    "        \n",
    "        # Mostrar classificação\n",
    "        print(\"\n",
    "Classificação automática:\")\n",
    "        for classe, tipo in classificacao.items():\n",
    "            print(f\"  {tipo}: {classe}\")\n",
    "        \n",
    "        # Estatísticas da classificação\n",
    "        tipos_count = {}\n",
    "        for tipo in classificacao.values():\n",
    "            tipos_count[tipo] = tipos_count.get(tipo, 0) + 1\n",
    "        \n",
    "        print(f\"\n",
    "Resumo da classificação:\")\n",
    "        for tipo, count in tipos_count.items():\n",
    "            print(f\"  {tipo}: {count} classes\")\n",
    "            \n",
    "    else:\n",
    "        print(\"❌ Análise de classes não pode prosseguir sem identificar a coluna correta\")\n",
    "else:\n",
    "    print(\"❌ Não é possível analisar - dados não carregados ou coluna de cliente não identificada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análise de Carteiras Mistas\n",
    "\n",
    "Com base na classificação Local/Offshore, identificamos clientes que possuem tanto ativos locais quanto offshore em suas carteiras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and coluna_cliente and coluna_classe and 'classificacao' in locals() and classificacao:\n",
    "    # Criar coluna de tipo de carteira no dataframe\n",
    "    df['tipo_carteira'] = df[coluna_classe].map(classificacao)\n",
    "    \n",
    "    print(\"=== ANÁLISE DE CARTEIRAS MISTAS ===\")\n",
    "    \n",
    "    # Agrupar por cliente e verificar tipos de carteira\n",
    "    clientes_tipos = df.groupby(coluna_cliente)['tipo_carteira'].unique()\n",
    "    \n",
    "    # Identificar clientes com carteiras mistas (local E offshore)\n",
    "    clientes_mistas = []\n",
    "    clientes_so_local = []\n",
    "    clientes_so_offshore = []\n",
    "    clientes_indefinido = []\n",
    "    \n",
    "    for cliente, tipos in clientes_tipos.items():\n",
    "        tipos_set = set(tipos)\n",
    "        \n",
    "        if 'LOCAL' in tipos_set and 'OFFSHORE' in tipos_set:\n",
    "            clientes_mistas.append(cliente)\n",
    "        elif 'LOCAL' in tipos_set and 'OFFSHORE' not in tipos_set:\n",
    "            clientes_so_local.append(cliente)\n",
    "        elif 'OFFSHORE' in tipos_set and 'LOCAL' not in tipos_set:\n",
    "            clientes_so_offshore.append(cliente)\n",
    "        else:\n",
    "            clientes_indefinido.append(cliente)\n",
    "    \n",
    "    print(f\"Clientes com carteiras MISTAS (local + offshore): {len(clientes_mistas)}\")\n",
    "    print(f\"Clientes APENAS locais: {len(clientes_so_local)}\")\n",
    "    print(f\"Clientes APENAS offshore: {len(clientes_so_offshore)}\")\n",
    "    print(f\"Clientes indefinidos: {len(clientes_indefinido)}\")\n",
    "    \n",
    "    # Mostrar exemplos de clientes com carteiras mistas\n",
    "    if clientes_mistas:\n",
    "        print(f\"\n",
    "Exemplos de clientes com carteiras mistas:\")\n",
    "        for i, cliente in enumerate(clientes_mistas[:3]):\n",
    "            print(f\"  {i+1}. {cliente}\")\n",
    "            cliente_data = df[df[coluna_cliente] == cliente]\n",
    "            for _, row in cliente_data.iterrows():\n",
    "                print(f\"     {row[coluna_classe]} ({row['tipo_carteira']})\")\n",
    "        \n",
    "        if len(clientes_mistas) > 3:\n",
    "            print(f\"  ... e mais {len(clientes_mistas) - 3} clientes com carteiras mistas\")\n",
    "    else:\n",
    "        print(\"⚠️ Nenhum cliente com carteiras mistas identificado\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Não é possível analisar carteiras mistas - dados incompletos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Identificação e Validação da Coluna de Valores Monetários\n",
    "\n",
    "Esta seção foca em encontrar a coluna que representa os valores monetários das posições e realizar uma validação básica (tipo de dado, valores nulos, mínimo, máximo, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Identificar coluna de valores\n",
    "    coluna_valor = None\n",
    "    if colunas_possiveis['valor']:\n",
    "        coluna_valor = colunas_possiveis['valor'][0]\n",
    "    else:\n",
    "        # Buscar colunas numéricas que possam ser valores\n",
    "        colunas_numericas = df.select_dtypes(include=[np.number]).columns\n",
    "        if len(colunas_numericas) > 0:\n",
    "            coluna_valor = colunas_numericas[0]  # Usar primeira coluna numérica\n",
    "    \n",
    "    if coluna_valor:\n",
    "        print(f\"=== ANÁLISE DE VALORES (usando coluna: {coluna_valor}) ===\")\n",
    "        print(f\"Tipo de dados: {df[coluna_valor].dtype}\")\n",
    "        print(f\"Valores nulos: {df[coluna_valor].isnull().sum()}\")\n",
    "        print(f\"Valor mínimo: {df[coluna_valor].min():,.2f}\")\n",
    "        print(f\"Valor máximo: {df[coluna_valor].max():,.2f}\")\n",
    "        print(f\"Valor médio: {df[coluna_valor].mean():,.2f}\")\n",
    "        print(f\"Soma total: {df[coluna_valor].sum():,.2f}\")\n",
    "        \n",
    "        # Verificar se há valores negativos ou zero\n",
    "        valores_negativos = (df[coluna_valor] < 0).sum()\n",
    "        valores_zero = (df[coluna_valor] == 0).sum()\n",
    "        \n",
    "        if valores_negativos > 0:\n",
    "            print(f\"⚠️ ATENÇÃO: {valores_negativos} valores negativos encontrados\")\n",
    "        if valores_zero > 0:\n",
    "            print(f\"⚠️ ATENÇÃO: {valores_zero} valores zerados encontrados\")\n",
    "            \n",
    "    else:\n",
    "        print(\"❌ Não foi possível identificar coluna de valores\")\n",
    "        print(\"Colunas numéricas disponíveis:\", df.select_dtypes(include=[np.number]).columns.tolist())\n",
    "else:\n",
    "    print(\"❌ Não é possível analisar valores - dados não carregados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Teste de Consolidação (Exemplo)\n",
    "\n",
    "Para verificar a lógica de consolidação, simulamos o processo para um cliente específico, somando os valores por classe de ativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and coluna_cliente and coluna_classe and coluna_valor:\n",
    "    print(\"=== TESTE DE CONSOLIDAÇÃO ===\")\n",
    "    \n",
    "    # Pegar cliente com carteira mista se disponível, senão qualquer cliente\n",
    "    if 'clientes_mistas' in locals() and clientes_mistas:\n",
    "        cliente_teste = clientes_mistas[0]\n",
    "        print(f\"Testando consolidação para cliente MISTO: {cliente_teste}\")\n",
    "    else:\n",
    "        cliente_teste = df[coluna_cliente].iloc[0]\n",
    "        print(f\"Testando consolidação para cliente: {cliente_teste}\")\n",
    "    \n",
    "    # Filtrar dados do cliente\n",
    "    df_cliente = df[df[coluna_cliente] == cliente_teste].copy()\n",
    "    \n",
    "    print(f\"\n",
    "Posições originais do cliente ({len(df_cliente)} registros):\")\n",
    "    for _, row in df_cliente.iterrows():\n",
    "        valor = row[coluna_valor]\n",
    "        classe = row[coluna_classe] \n",
    "        tipo = row.get('tipo_carteira', 'N/A')\n",
    "        print(f\"  {classe} | {valor:,.2f} | {tipo}\")\n",
    "    \n",
    "    # Simular consolidação simples - somar por classe\n",
    "    if 'tipo_carteira' in df_cliente.columns:\n",
    "        print(f\"\n",
    "Consolidação por classe de ativo:\")\n",
    "        consolidado = df_cliente.groupby(coluna_classe)[coluna_valor].sum().sort_values(ascending=False)\n",
    "        \n",
    "        total_cliente = consolidado.sum()\n",
    "        for classe, valor in consolidado.items():\n",
    "            percentual = (valor / total_cliente) * 100\n",
    "            print(f\"  {classe}: {valor:,.2f} ({percentual:.1f}%)\")\n",
    "        \n",
    "        print(f\"\n",
    "Total do cliente: {total_cliente:,.2f}\")\n",
    "        \n",
    "        # Verificar se soma bate com original\n",
    "        total_original = df_cliente[coluna_valor].sum()\n",
    "        if abs(total_cliente - total_original) < 0.01:  # tolerância para arredondamentos\n",
    "            print(\"✅ Consolidação OK - totais conferem\")\n",
    "        else:\n",
    "            print(f\"⚠️ ATENÇÃO: Diferença nos totais: {abs(total_cliente - total_original):,.2f}\")\n",
    "    else:\n",
    "        print(\"⚠️ Não é possível fazer consolidação completa - tipo de carteira não definido\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Não é possível testar consolidação - colunas essenciais não identificadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumo Final e Insights\n",
    "\n",
    "Coletamos os principais resultados da análise exploratória, que servirão de base para o desenvolvimento do notebook principal de consolidação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESUMO EXECUTIVO - INSIGHTS PARA CONSOLIDAÇÃO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"📊 DADOS CARREGADOS:\")\n",
    "    print(f\"   • Total de registros: {len(df):,}\")\n",
    "    print(f\"   • Clientes únicos: {df[coluna_cliente].nunique():,}\")\n",
    "    print(f\"   • Classes de ativo: {df[coluna_classe].nunique():,}\")\n",
    "    \n",
    "    if coluna_valor:\n",
    "        print(f\"   • Patrimônio total: {df[coluna_valor].sum():,.2f}\")\n",
    "    \n",
    "    print(f\"\n",
    "🔍 COLUNAS IDENTIFICADAS:\")\n",
    "    print(f\"   • Cliente: {coluna_cliente}\")\n",
    "    print(f\"   • Classe de Ativo: {coluna_classe}\")\n",
    "    print(f\"   • Valor: {coluna_valor}\")\n",
    "    \n",
    "    if 'classificacao' in locals():\n",
    "        print(f\"\n",
    "🏦 CLASSIFICAÇÃO LOCAL/OFFSHORE:\")\n",
    "        tipos_count = {}\n",
    "        for tipo in classificacao.values():\n",
    "            tipos_count[tipo] = tipos_count.get(tipo, 0) + 1\n",
    "        for tipo, count in tipos_count.items():\n",
    "            print(f\"   • {tipo}: {count} classes\")\n",
    "    \n",
    "    if 'clientes_mistas' in locals():\n",
    "        print(f\"\n",
    "👥 CLIENTES COM CARTEIRAS MISTAS:\")\n",
    "        print(f\"   • Local + Offshore: {len(clientes_mistas):,}\")\n",
    "        print(f\"   • Apenas Local: {len(clientes_so_local):,}\")\n",
    "        print(f\"   • Apenas Offshore: {len(clientes_so_offshore):,}\")\n",
    "    \n",
    "    print(f\"\n",
    "⚙️ PARÂMETROS PARA NOTEBOOK PRINCIPAL:\")\n",
    "    print(f\"   • COLUNA_CLIENTE = '{coluna_cliente}'\")\n",
    "    print(f\"   • COLUNA_CLASSE = '{coluna_classe}'\")\n",
    "    print(f\"   • COLUNA_VALOR = '{coluna_valor}'\")\n",
    "    \n",
    "    if 'termos_local' in locals():\n",
    "        print(f\"   • TERMOS_LOCAL = {termos_local}\")\n",
    "        print(f\"   • TERMOS_OFFSHORE = {termos_offshore}\")\n",
    "    \n",
    "    print(f\"\n",
    "✅ PRÓXIMOS PASSOS:\")\n",
    "    print(f\"   1. Usar os parâmetros acima no notebook principal\")\n",
    "    print(f\"   2. Implementar lógica de classificação local/offshore\")\n",
    "    print(f\"   3. Desenvolver consolidação por cliente + classe\")\n",
    "    print(f\"   4. Aplicar regras de recategorização se necessário\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ FALHA NO CARREGAMENTO - Verificar arquivo e tentar novamente\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
